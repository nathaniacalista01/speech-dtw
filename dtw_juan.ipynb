{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from python_speech_features import mfcc, delta\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "import numpy as np\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a {'template': 'd:\\\\Folder_Kuliah_Cadangan\\\\Sems_7\\\\Speech\\\\speech-dtw\\\\template\\\\a', 'testing': 'd:\\\\Folder_Kuliah_Cadangan\\\\Sems_7\\\\Speech\\\\speech-dtw\\\\testing\\\\a'}\n",
      "e {'template': 'd:\\\\Folder_Kuliah_Cadangan\\\\Sems_7\\\\Speech\\\\speech-dtw\\\\template\\\\e', 'testing': 'd:\\\\Folder_Kuliah_Cadangan\\\\Sems_7\\\\Speech\\\\speech-dtw\\\\testing\\\\e'}\n",
      "i {'template': 'd:\\\\Folder_Kuliah_Cadangan\\\\Sems_7\\\\Speech\\\\speech-dtw\\\\template\\\\i', 'testing': 'd:\\\\Folder_Kuliah_Cadangan\\\\Sems_7\\\\Speech\\\\speech-dtw\\\\testing\\\\i'}\n",
      "o {'template': 'd:\\\\Folder_Kuliah_Cadangan\\\\Sems_7\\\\Speech\\\\speech-dtw\\\\template\\\\o', 'testing': 'd:\\\\Folder_Kuliah_Cadangan\\\\Sems_7\\\\Speech\\\\speech-dtw\\\\testing\\\\o'}\n",
      "u {'template': 'd:\\\\Folder_Kuliah_Cadangan\\\\Sems_7\\\\Speech\\\\speech-dtw\\\\template\\\\u', 'testing': 'd:\\\\Folder_Kuliah_Cadangan\\\\Sems_7\\\\Speech\\\\speech-dtw\\\\testing\\\\u'}\n"
     ]
    }
   ],
   "source": [
    "TEMPLATE_DIR = os.path.join(os.getcwd(), 'template')\n",
    "TESTING_DIR = os.path.join(os.getcwd(), 'testing')\n",
    "\n",
    "VOWEL_LIST = ['a', 'e', 'i', 'o', 'u']\n",
    "DATA_DICT = dict()\n",
    "\n",
    "for vowel in VOWEL_LIST:\n",
    "  temp_dict = {\n",
    "    'template' : os.path.join(TEMPLATE_DIR, vowel),\n",
    "    'testing' : os.path.join(TESTING_DIR, vowel)\n",
    "  }\n",
    "  DATA_DICT[vowel] = temp_dict\n",
    "\n",
    "# List all the data into a single dictionary\n",
    "for k, v in DATA_DICT.items():\n",
    "  print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract si mfcc dari file path\n",
    "def extract_mfcc(file_path):\n",
    "  rate,signal = wav.read(file_path)\n",
    "  mfcc_features = mfcc(signal, rate, numcep=13)\n",
    "  mfcc_delta = delta(mfcc_features, 2)\n",
    "  mfcc_delta_delta = delta(mfcc_delta, 2)\n",
    "  return np.hstack((mfcc_features, mfcc_delta, mfcc_delta_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung jarak dari 1 test ke 1 template\n",
    "def calculate_dtw(template, test):\n",
    "  distance, _ = fastdtw(template, test, dist=euclidean)\n",
    "  return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cocokin 1 data test ke templates\n",
    "def speech_recognition(test, templates):\n",
    "  distances = []\n",
    "  for vowel, template in templates.items():\n",
    "    distance = calculate_dtw(template, test)\n",
    "    distances.append((vowel, distance))\n",
    "  # print(distances)\n",
    "  recognized_vowel = min(distances, key=lambda x: x[1])[0]\n",
    "  return recognized_vowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROCESS] Converting a\n",
      "[PROCESS] Converting e\n",
      "[PROCESS] Converting i\n",
      "[PROCESS] Converting o\n",
      "[PROCESS] Converting u\n"
     ]
    }
   ],
   "source": [
    "# Convert .m4a to .wav\n",
    "for k, v in DATA_DICT.items():\n",
    "  print(f\"[PROCESS] Converting {k}\")\n",
    "  template_files = os.listdir(v['template'])\n",
    "  testing_files = os.listdir(v['testing'])\n",
    "\n",
    "  adjusted_template_files = [os.path.join(v['template'], file) for file in template_files]\n",
    "  adjusted_testing_files = [os.path.join(v['testing'], file) for file in testing_files]\n",
    "\n",
    "  for file in adjusted_template_files:\n",
    "    m4a_audio = AudioSegment.from_file(file, format=\"m4a\")\n",
    "    out_file = file.replace(\".m4a\", \".wav\")\n",
    "    m4a_audio.export(out_file, format=\"wav\")\n",
    "\n",
    "  for file in adjusted_testing_files:\n",
    "    m4a_audio = AudioSegment.from_file(file, format=\"m4a\")\n",
    "    out_file = file.replace(\".m4a\", \".wav\")\n",
    "    m4a_audio.export(out_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROCESSING] 0 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\a\\a-(template).wav\n",
      "[PROCESSING] 1 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\a\\A-Template.wav\n",
      "[PROCESSING] 2 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\a\\a.wav\n",
      "[PROCESSING] 0 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\e\\e-(template).wav\n",
      "[PROCESSING] 1 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\e\\E-Template.wav\n",
      "[PROCESSING] 2 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\e\\e.wav\n",
      "[PROCESSING] 0 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\i\\I(template).wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROCESSING] 1 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\i\\I-Template.wav\n",
      "[PROCESSING] 2 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\i\\i.wav\n",
      "[PROCESSING] 0 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\o\\o(template).wav\n",
      "[PROCESSING] 1 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\o\\O-Template.wav\n",
      "[PROCESSING] 2 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\o\\o.wav\n",
      "[PROCESSING] 0 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\u\\u-(template).wav\n",
      "[PROCESSING] 1 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\u\\U-Template.wav\n",
      "[PROCESSING] 2 | Template d:\\Folder_Kuliah_Cadangan\\Sems_7\\Speech\\speech-dtw\\template\\u\\u.wav\n"
     ]
    }
   ],
   "source": [
    "# PROCESS TEMPLATES\n",
    "template1 = dict()\n",
    "template2 = dict()\n",
    "template3 = dict()\n",
    "for k, v in DATA_DICT.items():\n",
    "  wav_template_files = list(filter(lambda x: '.wav' in x, os.listdir(v['template'])))\n",
    "  adjusted_wav_template_files = [os.path.join(v['template'], file) for file in wav_template_files]\n",
    "\n",
    "  for i in range (len(adjusted_wav_template_files)):\n",
    "    template_file = adjusted_wav_template_files[i]\n",
    "    template_file_res = extract_mfcc(template_file)\n",
    "    \n",
    "    if (i == 0):\n",
    "      print(f\"[PROCESSING] {i} | Template {template_file}\")\n",
    "      template1[k] = template_file_res\n",
    "    elif (i == 1):\n",
    "      print(f\"[PROCESSING] {i} | Template {template_file}\")\n",
    "      template2[k] = template_file_res\n",
    "    else: # i == 2\n",
    "      print(f\"[PROCESSING] {i} | Template {template_file}\")\n",
    "      template3[k] = template_file_res\n",
    "\n",
    "# for k, v in template1.items():\n",
    "#   print(k,v)\n",
    "# for k, v in template2.items():\n",
    "#   print(k,v)\n",
    "# for k, v in template3.items():\n",
    "#   print(k,v)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROCESS] Evaluating a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROCESS] Evaluating e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROCESS] Evaluating i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROCESS] Evaluating o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROCESS] Evaluating u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nathan\n",
      "a\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'e', 'Speaker': 'Nathania'}\n",
      "i\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'e', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'e', 'Speaker': 'Nathania'}\n",
      "u\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'e', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'e', 'Speaker': 'Nathania'}\n",
      "e\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'e', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'e', 'Speaker': 'Nathania'}\n",
      "o\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'e', 'Speaker': 'Nathania'}\n",
      "Juan\n",
      "a\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'a', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathania'}\n",
      "i\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'i', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathania'}\n",
      "u\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathania'}\n",
      "e\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'e', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathania'}\n",
      "o\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathania'}\n",
      "Nathania\n",
      "a\n",
      "{'Detected Vowel': 'u', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'u', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'a', 'Speaker': 'Nathania'}\n",
      "i\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'u', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'i', 'Speaker': 'Nathania'}\n",
      "u\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'u', 'Speaker': 'Nathania'}\n",
      "e\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'u', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'e', 'Speaker': 'Nathania'}\n",
      "o\n",
      "{'Detected Vowel': 'u', 'Speaker': 'Nathan'}\n",
      "{'Detected Vowel': 'u', 'Speaker': 'Juan'}\n",
      "{'Detected Vowel': 'o', 'Speaker': 'Nathania'}\n"
     ]
    }
   ],
   "source": [
    "template_speaker_list = [\"Nathan\", \"Juan\", \"Nathania\"]\n",
    "summary_template_data = {\n",
    "  \"Nathan\" : {\n",
    "    \"a\" : [],\n",
    "    \"i\" : [],\n",
    "    \"u\" : [],\n",
    "    \"e\" : [],\n",
    "    \"o\" : []\n",
    "  },\n",
    "  \"Juan\"   : {\n",
    "    \"a\" : [],\n",
    "    \"i\" : [],\n",
    "    \"u\" : [],\n",
    "    \"e\" : [],\n",
    "    \"o\" : []\n",
    "  },\n",
    "  \"Nathania\" : {\n",
    "    \"a\" : [],\n",
    "    \"i\" : [],\n",
    "    \"u\" : [],\n",
    "    \"e\" : [],\n",
    "    \"o\" : []\n",
    "  },\n",
    "}\n",
    "\n",
    "# PROCESS TESTING\n",
    "for k, v in DATA_DICT.items():\n",
    "  print(f\"[PROCESS] Evaluating {k}\")\n",
    "  wav_testing_files = list(filter(lambda x: '.wav' in x, os.listdir(v['testing'])))\n",
    "  adjusted_wav_testing_files = [os.path.join(v['testing'], file) for file in wav_testing_files]\n",
    "\n",
    "  for i in range(len(adjusted_wav_testing_files)):\n",
    "    testing_file = adjusted_wav_testing_files[i]\n",
    "    testing_file_res = extract_mfcc(testing_file) \n",
    "    # Template 1\n",
    "    recognized_vowel_1 = speech_recognition(testing_file_res, template1)\n",
    "    # print(f\"\"\"Template Vowel: {k}  Speaker {template_speaker_list[0]} \\n\\t Detected Vowel: {recognized_vowel_1} Speaker {template_speaker_list[i]} \"\"\")\n",
    "\n",
    "    # Template 2\n",
    "    recognized_vowel_2 = speech_recognition(testing_file_res, template2)\n",
    "    # print(f\"\"\"Template Vowel: {k}  Speaker {template_speaker_list[1]} \\n\\t Detected Vowel: {recognized_vowel_2} Speaker {template_speaker_list[i]} \"\"\")\n",
    "\n",
    "    # Template 3\n",
    "    recognized_vowel_3 = speech_recognition(testing_file_res, template3)\n",
    "    # print(f\"\"\"Template Vowel: {k}  Speaker {template_speaker_list[2]} \\n\\t Detected Vowel: {recognized_vowel_3} Speaker {template_speaker_list[i]} \"\"\")\n",
    "\n",
    "\n",
    "    summary_template_data[template_speaker_list[0]][k].append({\n",
    "      \"Detected Vowel\" : recognized_vowel_1,\n",
    "      \"Speaker\" : template_speaker_list[i]\n",
    "    })\n",
    "    summary_template_data[template_speaker_list[1]][k].append({\n",
    "      \"Detected Vowel\" : recognized_vowel_2,\n",
    "      \"Speaker\" : template_speaker_list[i]\n",
    "    })\n",
    "    summary_template_data[template_speaker_list[2]][k].append({\n",
    "      \"Detected Vowel\" : recognized_vowel_3,\n",
    "      \"Speaker\" : template_speaker_list[i]\n",
    "    })\n",
    "\n",
    "\n",
    "for k, v in summary_template_data.items():\n",
    "  print(k)\n",
    "  for k_in, v_in in v.items():\n",
    "    print(k_in)\n",
    "    for data in v_in:\n",
    "      print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nathan\n",
      "accuracy_a 0.00\n",
      "accuracy_i 0.00\n",
      "accuracy_u 0.00\n",
      "accuracy_e 66.67\n",
      "accuracy_o 66.67\n",
      "template_accuracy 26.67\n",
      "\n",
      "Juan\n",
      "accuracy_a 33.33\n",
      "accuracy_i 33.33\n",
      "accuracy_u 0.00\n",
      "accuracy_e 33.33\n",
      "accuracy_o 100.00\n",
      "template_accuracy 40.00\n",
      "\n",
      "Nathania\n",
      "accuracy_a 33.33\n",
      "accuracy_i 33.33\n",
      "accuracy_u 33.33\n",
      "accuracy_e 33.33\n",
      "accuracy_o 33.33\n",
      "template_accuracy 33.33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_final_data = {\n",
    "  \"Nathan\" : {},\n",
    "  \"Juan\" : {},\n",
    "  \"Nathania\" : {}\n",
    "}\n",
    "\n",
    "for speaker_template, template_data in summary_template_data.items():\n",
    "  template_sum_accuracy = 0\n",
    "  for vowel_template, testing_data_list in template_data.items():\n",
    "    count = 0\n",
    "    correct_count = 0\n",
    "    for data in testing_data_list:\n",
    "      count += 1\n",
    "      if (data['Detected Vowel'] == vowel_template):\n",
    "        correct_count += 1\n",
    "\n",
    "    vowel_key_name = f\"accuracy_{vowel_template}\"\n",
    "    vowel_accuracy = correct_count / count * 100\n",
    "    summary_final_data[speaker_template][vowel_key_name] = f\"{vowel_accuracy:.2f}\"\n",
    "\n",
    "    template_sum_accuracy += vowel_accuracy\n",
    "\n",
    "  template_accuracy = template_sum_accuracy / 5\n",
    "  summary_final_data[speaker_template]['template_accuracy'] = f\"{template_accuracy:.2f}\"\n",
    "\n",
    "\n",
    "for speaker, accuracy_dict in summary_final_data.items():\n",
    "  print(speaker)\n",
    "  for k, v in accuracy_dict.items():\n",
    "    print(k, v)\n",
    "  print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
